{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dacon.io/competitions/official/236229/overview/description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Info.\n",
    "\n",
    "train.csv [파일] \n",
    "데이터 전처리 과정이 끝난 학습 데이터 (추가 데이터 전처리 과정을 진행하지 않습니다.)\n",
    "RF 모델 하이퍼파라미터를 제출 시, 해당 데이터로 자동적으로 학습됩니다.\n",
    "person_id: 유저별 고유 아이디\n",
    "Sex: 성별\n",
    "past_login_total: 과거(5월 8일 이전)에 로그인한 총 횟수\n",
    "past_1_month_login: 과거 1달간 로그인한 총 횟수\n",
    "past_1_week_login: 과거 1주간 로그인한 총 횟수\n",
    "sub_size: 과거에 데이콘 대회에서의 총 제출 수\n",
    "email_type: 가입한 이메일 종류\n",
    "phone_rat: 폰으로 접속한 비율\n",
    "apple_rat: 애플 기기로 접속한 비율\n",
    "login: 로그인 여부 \n",
    "\n",
    "\n",
    "sample_submission.csv [파일] - 제출 양식\n",
    "RF 모델을 학습시킬 모델 하이퍼파라미터 목록\n",
    "n_estimators:\n",
    "기본값: 10\n",
    "범위: 10 ~ 1000 사이의 양의 정수. 일반적으로 값이 클수록 모델 성능이 좋아지지만, 계산 비용과 시간도 증가합니다.\n",
    "criterion:\n",
    "기본값: 'gini'\n",
    "옵션: 'gini', 'entropy'. 'gini'는 진니 불순도를, 'entropy'는 정보 이득을 기준으로 합니다.\n",
    "max_depth:\n",
    "기본값: None\n",
    "범위: None 또는 양의 정수. None으로 설정하면 노드가 모든 리프가 순수해질 때까지 확장됩니다. 양의 정수를 설정하면 트리의 최대 깊이를 제한합니다.\n",
    "min_samples_split:\n",
    "기본값: 2\n",
    "범위: 2 이상의 정수 또는 0과 1 사이의 실수 (비율을 나타냄, (0, 1] ). 내부 노드를 분할하기 위해 필요한 최소 샘플 수를 지정합니다.\n",
    "min_samples_leaf:\n",
    "기본값: 1\n",
    "범위: 1 이상의 정수 또는 0과 0.5 사이의 실수 (비율을 나타냄, (0, 0.5] ). 리프 노드가 가져야 하는 최소 샘플 수를 지정합니다.\n",
    "min_weight_fraction_leaf:\n",
    "기본값: 0.0\n",
    "범위: 0.0에서 0.5 사이의 실수. 리프 노드에 있어야 하는 샘플의 최소 가중치 비율을 지정합니다.\n",
    "max_features:\n",
    "기본값: 'auto'\n",
    "옵션: 'auto', 'sqrt', 'log2', None 또는 양의 정수/실수. 최적의 분할을 찾기 위해 고려할 특성의 수 또는 비율을 지정합니다. 'auto'는 모든 특성을 사용함을 의미하며, 'sqrt'와 'log2'는 각각 특성의 제곱근과 로그2를 사용합니다. None은 'auto'와 동일하게 모든 특성을 의미합니다.\n",
    "max_leaf_nodes:\n",
    "기본값: None\n",
    "범위: None 또는 양의 정수. 리프 노드의 최대 수를 제한합니다. None은 무제한을 의미합니다.\n",
    "min_impurity_decrease:\n",
    "기본값: 0.0\n",
    "범위: 0.0 이상의 실수. 노드를 분할할 때 감소해야 하는 불순도의 최소량을 지정합니다.\n",
    "bootstrap:\n",
    "기본값: True\n",
    "옵션: True, False. True는 부트스트랩 샘플을 사용하여 개별 트리를 학습시킵니다. False는 전체 데이터셋을 사용하여 각 트리를 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./rf/train.csv')\n",
    "test = pd.read_csv('rf/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>bootstrap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators criterion  max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0          1000   entropy          4                  3                 4   \n",
       "\n",
       "   min_weight_fraction_leaf  max_features  max_leaf_nodes  \\\n",
       "0                         0           NaN             NaN   \n",
       "\n",
       "   min_impurity_decrease  bootstrap  \n",
       "0                      0       True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut,train_test_split , GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능확인 코드\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    roc_score = roc_auc_score(y_test, pred)\n",
    "    pr_score = average_precision_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    f2 = fbeta_score(y_test, pred, beta=2)\n",
    "    # G-mean 계산\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "\n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도 : {1:.4f}, 재현율:{2:.4f},F1 스코어:{3:.4f}, f2 :{4:.4f}'.format(accuracy, precision, recall, f1, f2))\n",
    "    print('ROC 스코어: {0:.4f}, PR 스코어 : {1:.4f}, G-mean : {2:.4f}'.format(roc_score, pr_score, gmean))\n",
    "\n",
    "# 임계값에 따른 오차행렬및 스코어 -------->#임계값 최적 : 재현율기준(0.1)/f1기준(0.3)\n",
    "from sklearn.preprocessing import Binarizer\n",
    "thresholds = [0.1,0.15,0.2,0.25,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        # ROC 커브 계산\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(\"임곗값:\", custom_threshold)\n",
    "        print(\"ROC_AUC:\", roc_auc)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        print(\"---------------------------------------------------------\")\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def roc(model,name) :\n",
    "    # 테스트 데이터에 대한 예측 확률 계산\n",
    "    pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # ROC 커브 계산\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred)\n",
    "\n",
    "    # AUC 계산\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # ROC 커브에 AUC 면적에 색을 입히는 코드 수정\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # ROC 커브 시각화 및 AUC 면적 색칠\n",
    "    plt.fill_between(fpr, tpr, color='palegoldenrod', alpha=0.4, label=f'Area under curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot(fpr, tpr, color='peru', lw=2)\n",
    "\n",
    "    # 기본 설정\n",
    "    plt.plot([0, 1], [0, 1], color='darkorange', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person_id', 'Sex', 'past_login_total', 'past_1_month_login',\n",
       "       'past_1_week_login', 'sub_size', 'email_type', 'phone_rat', 'apple_rat',\n",
       "       'login'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['person_id', 'Sex', 'past_login_total', 'past_1_month_login',\n",
    "       'past_1_week_login', 'sub_size', 'email_type', 'phone_rat', 'apple_rat',\n",
    "       ]]\n",
    "y = df[['login']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test 분리 \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators:\n",
    "기본값: 10\n",
    "범위: 10 ~ 1000 사이의 양의 정수. 일반적으로 값이 클수록 모델 성능이 좋아지지만, 계산 비용과 시간도 증가합니다.\n",
    "criterion:\n",
    "기본값: 'gini'\n",
    "옵션: 'gini', 'entropy'. 'gini'는 지니 불순도를, 'entropy'는 정보 이득을 기준으로 합니다.\n",
    "max_depth:\n",
    "기본값: None\n",
    "범위: None 또는 양의 정수. None으로 설정하면 노드가 모든 리프가 순수해질 때까지 확장됩니다. 양의 정수를 설정하면 트리의 최대 깊이를 제한합니다.\n",
    "min_samples_split:\n",
    "기본값: 2\n",
    "범위: 2 이상의 정수 또는 0과 1 사이의 실수 (비율을 나타냄, (0, 1] ). 내부 노드를 분할하기 위해 필요한 최소 샘플 수를 지정합니다.\n",
    "min_samples_leaf:\n",
    "기본값: 1\n",
    "범위: 1 이상의 정수 또는 0과 0.5 사이의 실수 (비율을 나타냄, (0, 0.5] ). 리프 노드가 가져야 하는 최소 샘플 수를 지정합니다.\n",
    "min_weight_fraction_leaf:\n",
    "기본값: 0.0\n",
    "범위: 0.0에서 0.5 사이의 실수. 리프 노드에 있어야 하는 샘플의 최소 가중치 비율을 지정합니다.\n",
    "max_features:\n",
    "기본값: 'auto'\n",
    "옵션: 'auto', 'sqrt', 'log2', None 또는 양의 정수/실수. 최적의 분할을 찾기 위해 고려할 특성의 수 또는 비율을 지정합니다. 'auto'는 모든 특성을 사용함을 의미하며, 'sqrt'와 'log2'는 각각 특성의 제곱근과 로그2를 사용합니다. None은 'auto'와 동일하게 모든 특성을 의미합니다.\n",
    "max_leaf_nodes:\n",
    "기본값: None\n",
    "범위: None 또는 양의 정수. 리프 노드의 최대 수를 제한합니다. None은 무제한을 의미합니다.\n",
    "min_impurity_decrease:\n",
    "기본값: 0.0\n",
    "범위: 0.0 이상의 실수. 노드를 분할할 때 감소해야 하는 불순도의 최소량을 지정합니다.\n",
    "bootstrap:\n",
    "기본값: True\n",
    "옵션: True, False. True는 부트스트랩 샘플을 사용하여 개별 트리를 학습시킵니다. False는 전체 데이터셋을 사용하여 각 트리를 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hangil\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[227   3]\n",
      " [ 20  12]]\n",
      "정확도: 0.9122, 정밀도 : 0.8000, 재현율:0.3750,F1 스코어:0.5106, f2 :0.4196\n",
      "ROC 스코어: 0.6810, PR 스코어 : 0.3763, G-mean : 0.6084\n",
      "임곗값: 0.1\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[189  41]\n",
      " [ 11  21]]\n",
      "정확도: 0.8015, 정밀도 : 0.3387, 재현율:0.6562,F1 스코어:0.4468, f2 :0.5526\n",
      "ROC 스코어: 0.7390, PR 스코어 : 0.2643, G-mean : 0.7343\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.15\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[197  33]\n",
      " [ 14  18]]\n",
      "정확도: 0.8206, 정밀도 : 0.3529, 재현율:0.5625,F1 스코어:0.4337, f2 :0.5028\n",
      "ROC 스코어: 0.7095, PR 스코어 : 0.2520, G-mean : 0.6941\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.2\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[202  28]\n",
      " [ 16  16]]\n",
      "정확도: 0.8321, 정밀도 : 0.3636, 재현율:0.5000,F1 스코어:0.4211, f2 :0.4651\n",
      "ROC 스코어: 0.6891, PR 스코어 : 0.2429, G-mean : 0.6627\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.25\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[214  16]\n",
      " [ 16  16]]\n",
      "정확도: 0.8779, 정밀도 : 0.5000, 재현율:0.5000,F1 스코어:0.5000, f2 :0.5000\n",
      "ROC 스코어: 0.7152, PR 스코어 : 0.3111, G-mean : 0.6821\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.3\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[217  13]\n",
      " [ 17  15]]\n",
      "정확도: 0.8855, 정밀도 : 0.5357, 재현율:0.4688,F1 스코어:0.5000, f2 :0.4808\n",
      "ROC 스코어: 0.7061, PR 스코어 : 0.3160, G-mean : 0.6650\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.4\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[224   6]\n",
      " [ 20  12]]\n",
      "정확도: 0.9008, 정밀도 : 0.6667, 재현율:0.3750,F1 스코어:0.4800, f2 :0.4110\n",
      "ROC 스코어: 0.6745, PR 스코어 : 0.3263, G-mean : 0.6043\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.5\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[227   3]\n",
      " [ 20  12]]\n",
      "정확도: 0.9122, 정밀도 : 0.8000, 재현율:0.3750,F1 스코어:0.5106, f2 :0.4196\n",
      "ROC 스코어: 0.6810, PR 스코어 : 0.3763, G-mean : 0.6084\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.6\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[227   3]\n",
      " [ 25   7]]\n",
      "정확도: 0.8931, 정밀도 : 0.7000, 재현율:0.2188,F1 스코어:0.3333, f2 :0.2536\n",
      "ROC 스코어: 0.6029, PR 스코어 : 0.2485, G-mean : 0.4646\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.7\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[228   2]\n",
      " [ 26   6]]\n",
      "정확도: 0.8931, 정밀도 : 0.7500, 재현율:0.1875,F1 스코어:0.3000, f2 :0.2206\n",
      "ROC 스코어: 0.5894, PR 스코어 : 0.2399, G-mean : 0.4311\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.8\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[229   1]\n",
      " [ 29   3]]\n",
      "정확도: 0.8855, 정밀도 : 0.7500, 재현율:0.0938,F1 스코어:0.1667, f2 :0.1136\n",
      "ROC 스코어: 0.5447, PR 스코어 : 0.1810, G-mean : 0.3055\n",
      "---------------------------------------------------------\n",
      "임곗값: 0.9\n",
      "ROC_AUC: 0.8425271739130434\n",
      "오차행렬\n",
      "[[229   1]\n",
      " [ 30   2]]\n",
      "정확도: 0.8817, 정밀도 : 0.6667, 재현율:0.0625,F1 스코어:0.1143, f2 :0.0763\n",
      "ROC 스코어: 0.5291, PR 스코어 : 0.1562, G-mean : 0.2495\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=17, \n",
    "                            n_estimators=1000,\n",
    "                            criterion='entropy',\n",
    "                            max_depth=4, \n",
    "                            min_samples_split=4,\n",
    "                            min_samples_leaf=3,\n",
    "                            min_weight_fraction_leaf = 0,\n",
    "                            max_features = None,\n",
    "                            max_leaf_nodes = None,\n",
    "                            min_impurity_decrease = 0,\n",
    "                            bootstrap = True)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_pred_proba = rf.predict_proba(X_test)\n",
    "\n",
    "get_clf_eval(y_test, rf_pred)\n",
    "get_eval_by_threshold(y_test , rf_pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_state=17, \n",
    "                            n_estimators=1050,\n",
    "                            criterion='entropy',\n",
    "                            max_depth=4, \n",
    "                            min_samples_split=3,\n",
    "                            min_samples_leaf=4,\n",
    "                            min_weight_fraction_leaf = 0,\n",
    "                            max_features = None,\n",
    "                            max_leaf_nodes = None,\n",
    "                            min_impurity_decrease = 0,\n",
    "                            bootstrap = True\n",
    "0.8296949944656254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차 3/18\n",
    "{'bootstrap': True,\n",
    " 'max_depth': 4,\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 3,\n",
    " 'n_estimators': 1000}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#최적 파라미터 값 출력\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "#최적 파라미터 값 출력\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
